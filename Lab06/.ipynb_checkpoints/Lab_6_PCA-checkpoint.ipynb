{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 88 - Data Science in Genetics and Genomics, 03/30/20\n",
    "## Due Monday, 04/06/20 @ 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by Jonathan Fischer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the modules we'll need\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "plt.style.use('fivethirtyeight')\n",
    "from client.api.notebook import Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA finds a good way to summarize your data using fewer dimensions than you started with. The covariance (aka the \"shape\") of your data dictates how easily it can do this. Data with highly correlated features has many redundancies and can thus be represented by fewer dimensions more easily. Let's examine two examples of the utility of PCA when analyzing sequencing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on genotype data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with an example of using PCA to help distguingish among individuals with various ancestries. The original data come from the HapMap consortium and consisted of SNP readings from a genotyping array along with a description of the population of the individual whose genotype has been measured. I've processed these data to only look at chromosome 22 (for computational purposes) and to convert each entry to a 0, 1, or 2. This number indicates the number of mutant alleles at a particular locus. In this case you can just think of this as counting how often an individual had the allele that is rarer in the overall population at a given site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the genotype information and population labels\n",
    "geno_mat = pd.read_csv('https://raw.githubusercontent.com/ds-connectors/Data88-Genetics_and_Genomics/master/Lab06/chr22_all_genotypes.csv')\n",
    "pop_labs = pd.read_csv('https://raw.githubusercontent.com/ds-connectors/Data88-Genetics_and_Genomics/master/Lab06/HapMap_pop_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows are loci, columns are individuals\n",
    "print('We are using ' + str(geno_mat.shape[0]) + ' loci to examine ' + str(geno_mat.shape[1]) + ' individuals from ' + str(len(np.unique(pop_labs))) + ' labeled populations.')\n",
    "      \n",
    "geno_mat.iloc[0:10, 0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see how the population labels look. The cell below the table shows the different populations which are being considered in the experiment. They span Europe, Asia, and Africa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_labs.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASW - African ancestry in Southwest USA<br/>\n",
    "CEU - Utah residents with Northern and Western European ancestry<br/>\n",
    "CHD - Chinese in Denver<br/>\n",
    "GIH - Gujarati Indians in Houston<br/>\n",
    "JPT_CHB - Japanese in Tokyo and Chinese in Beijing<br/>\n",
    "MEX - Mexican ancestry in Los Angeles<br/>\n",
    "MKK - Maasai in Kinyawa, Kenya<br/>\n",
    "TSI - Toscani in Italy<br/>\n",
    "YRI - Yoruba in Ibadan, Nigeria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply PCA to these data and see whether individuals with ancestry from the same or geographically proximate populations cluster near one another. We start by standardizing our matrix and running the PCA algorithm. Standardizing consists of subtracting the column mean from each column and then dividing by the standard deviation of that column. This step isn't always necessary, but often helps for reasons I'll only briefly touch on here.\n",
    "\n",
    "First, it removes the mean which could potentially dominate our signal (see this post https://stats.stackexchange.com/questions/22329/how-does-centering-the-data-get-rid-of-the-intercept-in-regression-and-pca). Subtraction of the mean is called \"centering\" our data. Second, it puts all variables on the same scale such that quantities with naturally higher variances don't dominate (this is \"scaling\"). Depending on your data, the scaling step may or may not be a good idea. It's a bit of an art and knowing what to do will come with experience. For now we'll go ahead and scale. This link (https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html) shows what can happen if we don't scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute column means and standard deviations\n",
    "geno_means = np.mean(geno_mat, axis = 1)\n",
    "geno_sds = np.std(geno_mat, axis = 1)\n",
    "\n",
    "# standardize the matrix\n",
    "y = (geno_mat.T - geno_means) / geno_sds\n",
    "\n",
    "# run PCA with 100 components\n",
    "geno_pca = PCA(n_components=100)\n",
    "geno_pca.fit(y.T)\n",
    "geno_comps = geno_pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good diagnostic to perform after running PCA is to take a look at the singular values to see how successfully your data were able to be summarized with fewer dimensions. These singular values essentially tell us how important the corresponding principal component is in summarizing our data. Here we find a pretty steep drop-off after the first two singular values, meaning our data can be well-described using only two dimensions. How convenient for plotting!<br/>\n",
    "These singular values can be converted to something more intuitive, the proportion of variation explained. These values tell us how much of the total variation in our data were captured by each respective principal component. In this case, we see the top PC captures 8-9% of the total variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(geno_pca.singular_values_)\n",
    "plt.title('Singular values')\n",
    "plt.subplot(122)\n",
    "plt.plot(geno_pca.explained_variance_ratio_)\n",
    "plt.title('Proportion of variation explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the projection of our data to 2 dimensions. Remember that our original data consisted of over 20k genes, and we're trying to condense all of this information down to effectively 2 \"new genes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projections using the first 2 PCs. Color the points by population labels\n",
    "i = 0\n",
    "j = 1\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'asw'], uncorrected_comps[j, pop_labs['pop'] == 'asw'], 'x', c = 'red')\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'ceu'], uncorrected_comps[j, pop_labs['pop'] == 'ceu'], 'x', c = 'pink')\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'chd'], uncorrected_comps[j, pop_labs['pop'] == 'chd'], 'x', c = 'orange')\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'gih'], uncorrected_comps[j, pop_labs['pop'] == 'gih'], 'x', c = 'green')\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'jpt_chb'], uncorrected_comps[j, pop_labs['pop'] == 'jpt_chb'], 'x', c = 'cyan')\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'mex'], uncorrected_comps[j, pop_labs['pop'] == 'mex'], 'x', c = 'blue')\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'mkk'], uncorrected_comps[j, pop_labs['pop'] == 'mkk'], 'x', c = 'violet')\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'tsi'], uncorrected_comps[j, pop_labs['pop'] == 'tsi'], 'x', c = 'purple')\n",
    "plt.plot(uncorrected_comps[i, pop_labs['pop'] == 'yri'], uncorrected_comps[j, pop_labs['pop'] == 'yri'], 'x', c = 'black')\n",
    "\n",
    "plt.legend(['ASW', 'CEU', 'CHD', 'GIH', 'JPT_CHB', 'MEX', 'MKK', 'TSI', 'YRI'], loc = 'upper left', bbox_to_anchor = (1,1))\n",
    "plt.title('Projected Data colored by population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1. Can you see evidence of the presence of different continents in the figure? If so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. A handful of the populations roughly overlap one another in the figure. Which ones make sense to you, and which ones do not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. A few of the populations seem to lie between apparent \"endpoints\" in the figure. Do you have any theories for why this might be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A4. The original figure displayed above only shows the results of comparing the first two principal components. To instead compare PCs 2 and 3, change \"i = 0\" to \"i = 2\" and re-generate the figure. Do any of the previously overlapping population groups which surprised you now show better separation? What does this imply about the information contained by PCs 1 and 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A5. From what you've learned about PCA, how would you explain the fact that different population groups seem to occupy different amounts of space in the figure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PCA to demonstrate batch effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In genetics and genomics, batch effects are one of the biggest problems which sometimes affect our data. PCA is a commonly used to search for these effects because they typically comprise a dominant source of variation which should appear in early PCs. Here we'll show how batch effects can introduce false signal in real RNA-seq data. These data come from the Geuvadis project and consist of 462 RNA-seq experiments performed on blood samples across 5 different populations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided data include reads which have not been corrected for batch, those which have, and the metadata detailing which lab performed the sequencing as well as the population of each individual. The data have already been normalized and log-transformed. Batch effect correction can often be performed using linear models, and that's what I did here. We will discuss how to do this when we cover that topic in a couple of weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uncorrected/corrected RNA-seq reads and sample metadata\n",
    "expression_uncorrected = pd.read_csv('https://raw.githubusercontent.com/ds-connectors/Data88-Genetics_and_Genomics/master/Lab06/geuv_batch.csv').T\n",
    "expression_corrected = pd.read_csv('https://raw.githubusercontent.com/ds-connectors/Data88-Genetics_and_Genomics/master/Lab06/geuv_corrected.csv').T\n",
    "metadata = pd.read_csv('https://raw.githubusercontent.com/ds-connectors/Data88-Genetics_and_Genomics/master/Lab06/geuv_meta.csv').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA on the uncorrected data\n",
    "uncorrected_means = np.mean(expression_uncorrected, axis = 0)\n",
    "uncorrected_sds = np.std(expression_uncorrected, axis = 0)\n",
    "\n",
    "y_uncorrected = (expression_uncorrected - uncorrected_means) / uncorrected_sds\n",
    "\n",
    "pca_uncorrected = PCA(n_components=100)\n",
    "pca_uncorrected.fit(y_uncorrected.T)\n",
    "uncorrected_comps = pca_uncorrected.components_\n",
    "\n",
    "# Let's look at the singular values and proportion of variation explained.\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(pca_uncorrected.singular_values_)\n",
    "plt.title('Singular values')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(pca_uncorrected.explained_variance_ratio_)\n",
    "plt.title('Proportion of variation explained')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at the projections of our samples before correcting for any batch effects. \n",
    "# We'll color by both batch and population.\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[2,:]==1], uncorrected_comps[1,metadata.iloc[2,:]==1], 'x', c = 'black')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[2,:]==2], uncorrected_comps[1,metadata.iloc[2,:]==2], 'x', c = 'red')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[2,:]==3], uncorrected_comps[1,metadata.iloc[2,:]==3], 'x', c = 'yellow')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[2,:]==4], uncorrected_comps[1,metadata.iloc[2,:]==4], 'x', c = 'green')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[2,:]==5], uncorrected_comps[1,metadata.iloc[2,:]==5], 'x', c = 'cyan')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[2,:]==6], uncorrected_comps[1,metadata.iloc[2,:]==6], 'x', c = 'blue')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[2,:]==7], uncorrected_comps[1,metadata.iloc[2,:]==7], 'x', c = 'magenta')\n",
    "plt.legend(['1', '2', '3', '4', '5', '6', '7'], loc = 'upper right', bbox_to_anchor = (1,1))\n",
    "plt.title('Colored by batch (uncorrected)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[3,:]=='British'], uncorrected_comps[1,metadata.iloc[3,:]=='British'], 'x', c = 'black')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[3,:]=='Finland'], uncorrected_comps[1,metadata.iloc[3,:]=='Finland'], 'x', c = 'red')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[3,:]=='Tuscan'], uncorrected_comps[1,metadata.iloc[3,:]=='Tuscan'], 'x', c = 'yellow')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[3,:]=='Utah'], uncorrected_comps[1,metadata.iloc[3,:]=='Utah'], 'x', c = 'green')\n",
    "plt.plot(uncorrected_comps[0,metadata.iloc[3,:]=='Yoruba'], uncorrected_comps[1,metadata.iloc[3,:]=='Yoruba'], 'x', c = 'cyan')\n",
    "\n",
    "\n",
    "plt.legend(['British', 'Finnish', 'Tuscan', 'Utahn', 'Yoruban'], loc = 'upper left', bbox_to_anchor = (1,1))\n",
    "plt.title('Colored by population (uncorrected)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's repeat, but for the corrected data\n",
    "corrected_means = np.mean(expression_corrected, axis = 0)\n",
    "corrected_sds = np.std(expression_corrected, axis = 0)\n",
    "\n",
    "y_corrected = (expression_corrected - corrected_means) / corrected_sds\n",
    "\n",
    "pca_corrected = PCA(n_components=100)\n",
    "pca_corrected.fit(y_corrected.T)  \n",
    "corrected_comps = pca_corrected.components_\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(pca_corrected.singular_values_)\n",
    "plt.title('Singular values')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(pca_corrected.explained_variance_ratio_)\n",
    "plt.title('Proportion of variation explained')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now look at the projections of the corrected data, again coloring by batch and population.\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(corrected_comps[0,metadata.iloc[2,:]==1], corrected_comps[1,metadata.iloc[2,:]==1], 'x', c = 'black')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[2,:]==2], corrected_comps[1,metadata.iloc[2,:]==2], 'x', c = 'red')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[2,:]==3], corrected_comps[1,metadata.iloc[2,:]==3], 'x', c = 'yellow')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[2,:]==4], corrected_comps[1,metadata.iloc[2,:]==4], 'x', c = 'green')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[2,:]==5], corrected_comps[1,metadata.iloc[2,:]==5], 'x', c = 'cyan')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[2,:]==6], corrected_comps[1,metadata.iloc[2,:]==6], 'x', c = 'blue')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[2,:]==7], corrected_comps[1,metadata.iloc[2,:]==7], 'x', c = 'magenta')\n",
    "plt.legend(['1', '2', '3', '4', '5', '6', '7'], loc = 'best')\n",
    "plt.title('Colored by batch (corrected)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(corrected_comps[0,metadata.iloc[3,:]=='British'], corrected_comps[1,metadata.iloc[3,:]=='British'], 'x', c = 'black')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[3,:]=='Finland'], corrected_comps[1,metadata.iloc[3,:]=='Finland'], 'x', c = 'red')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[3,:]=='Tuscan'], corrected_comps[1,metadata.iloc[3,:]=='Tuscan'], 'x', c = 'yellow')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[3,:]=='Utah'], corrected_comps[1,metadata.iloc[3,:]=='Utah'], 'x', c = 'green')\n",
    "plt.plot(corrected_comps[0,metadata.iloc[3,:]=='Yoruba'], corrected_comps[1,metadata.iloc[3,:]=='Yoruba'], 'x', c = 'cyan')\n",
    "\n",
    "\n",
    "plt.legend(['British', 'Finnish', 'Tuscan', 'Utahn', 'Yoruban'], loc = 'upper left', bbox_to_anchor = (1,1))\n",
    "plt.title('Colored by population (corrected)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Compare the plots colored by batch before and after correction. Do you think PCA was able to demonstrate the presence of batch effects? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. Which populations, if any, seem to be most distinguishable from the others on the basis of gene expression? Does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. Does it seem easier to separate populations via PCA using genotype or gene expression data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4. Why do you think the RNA-seq reads were normalized and log-transformed prior to performing PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B5. By comparing the shapes of the variation explained plots for the genotype and RNA-seq data, which data set do you think was easier to compress?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = Notebook('Lab06_PCA.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the assignment.\n",
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
