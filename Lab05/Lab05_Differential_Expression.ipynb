{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Differential Expression (3/16/20)\n",
    "## by Jonathan Fischer and Courtney Rauchman \n",
    "## due 3/23/20 @ 11:59 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the modules we'll need\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "plt.style.use('fivethirtyeight')\n",
    "from client.api.notebook import Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we're going to explore one of the most central topics in not only genomics, but all of statistics--hypothesis testing. In particular, we're interested in testing whether two populations have different means. In research, this often corresponds to determining whether a gene is \"differentially expressed\" in two different conditions. Examples include healthy/diseased, old/young, men/women, and liver/brain. Let's get started with some simulations to get a handle on things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I : The t-test and rank-sum test for differences in means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test is used to test whether there is evidence that the means of two populations are different. It assumes that both populations are normally distributed. Depending on the variation, it may also assume that the variances are equal. Today we're going to explore the most common version of the t-test with normal data and then show it how it fails when the data are not normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate two groups of 50 observations from standard normal distributions (mean 0, sd 1)\n",
    "\n",
    "# hint: np.random.normal(mean, sd, number of observations)\n",
    "norm_obs_1 = ?\n",
    "norm_obs_2 = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have two sets of 50 normal RVs and want to test whether the means of the populations they come from are different. To start, determine the null and alternative hypotheses below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "null hypothesis: mean_1 == mean_2\n",
    "    \n",
    "alternative hypothesis: mean_1 != mean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the t-test on our data and return the p-value. What do you expect on average?\n",
    "# The p-value will be random because your observations are random. That is, if you re-run the prior cell \n",
    "# and then this one, you will get a different p-value.\n",
    "\n",
    "# hint: stats.ttest_ind(group1, group2)[1] returns the p-value. [0] returns the test statistic\n",
    "p_val = ?\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One iteration can only tell us so much. Let's run it a bunch of times to see what happens! We want to make sure our test isn't too sensitive when the null is true. Based on the histogram, how often do we expect to incorrectly reject the null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 10000 sets of observations and do the t-test each time. Store the p-values so we can examine them.\n",
    "# Initialize the list to store p-values (you can just use [])\n",
    "# Use a for loop to iteratively generate the p-values. In each iteration, draw two groups of \n",
    "# 50 standard normal observations and perform a t-test. Compute and append the p-value \n",
    "# compute with p = (stats.ttest_ind(group1, group2)[1])\n",
    "# and append with p_values_1.append(p)\n",
    "\n",
    "p_values_1 = ?\n",
    "for i in np.arange(?):      # we should replace the ? here with the number of simulations we want to perform\n",
    "    norm_obs_1 = ?          # use the syntax we learned in the first cell\n",
    "    norm_obs_2 = ?          # remember we want both sets of 50 observations to come from N(0,1) distributions\n",
    "                            # perform appending on this line\n",
    "    \n",
    "# What does the distribution of p-values look like? Let's investigate by making a histogram.\n",
    "# Fill in the correct arguments to plt.hist; use 20 bins and density = True\n",
    "plt.hist(?)\n",
    "plt.title('t-test, N(0,1) vs N(0,1)')\n",
    "plt.xlabel('p-value')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about when the means are different? The ability of a test to correctly reject the null is known as its power. Let's examine the behavior of the t-test for a moderate difference in means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the preceding cell, but instead draw one group from a N(0,1) and the other from a N(0.2, 1)\n",
    "?\n",
    "    \n",
    "# What does the distribution of p-values look like?\n",
    "plt.hist(?)\n",
    "plt.title('t-test, N(0,1) vs N(0.2,1)')\n",
    "plt.xlabel('p-value')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that the t-test performs sensibly when the data are normally distributed. Now let's examine what happens when we violate this assumption. The Cauchy distribution is a symmetric distribution that happens to have extremely heavy tails, meaning it frequently produces values far away from its center. Let's see how it looks--run the code below a few times and note what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare histograms and density estimates for 1000 randomly sampled Cauchy and standard normal RVs.\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "sns.distplot(stats.cauchy.rvs(loc=0, scale=1, size=1000), kde=True)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Cauchy')\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.distplot(np.random.normal(0, 1, 1000), kde=True)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Gaussian')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test tests for differences in means, whereas the rank-sum test tests for something called \"stochastic dominance\". Loosely speaking, let's interpret this to mean a shift in the distribution. For symmetric distributions, this is equivalent to differences in means or medians. Let's evaluate how the p-values for two two tests differ on normal- and Cauchy-distributed data. (Note: the rank-sum test has a few names. These include the Mann-Whitney U test and the Wilcoxon rank-sum test. I usually just say \"rank-sum test\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t-test on Gaussian and Cauchy data. \n",
    "# Set location = .2 and n_trials = 10000\n",
    "# (stats.ttest_ind(group1, group2)[1])\n",
    "\n",
    "# Set parameter values\n",
    "location = ?\n",
    "n_trials = ?\n",
    "# Initialize lists to store p-values\n",
    "t_p_normal_vec = ?\n",
    "t_p_cauchy_vec = ?\n",
    "\n",
    "# For loop to iterate over number of simulated trials.\n",
    "for _ in np.arange(?):\n",
    "    normal_obs_1 = np.random.normal(?)    # draw 50 observations from a N(0,1)\n",
    "    normal_obs_2 = np.random.normal(?)    # draw 50 observations from a N(location,1)\n",
    "    cauchy_obs_1 = stats.cauchy.rvs(?)    # draw 50 observations from a Cauchy(0,1)\n",
    "    cauchy_obs_2 = stats.cauchy.rvs(?)    # draw 50 observations from a Cauchy(location,1)\n",
    "                                          # append normal p-values to t_p_normal_vec\n",
    "                                          # append Cauchy p-values to t_p_cauchy_vec\n",
    "\n",
    "# Make a histogram with the normal p-values first and the Cauchy p-values second.\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(?, bins = 20, density = True, color = 'Blue', alpha = 0.5) # plot the normal (Gaussian) p-values\n",
    "plt.hist(?, bins = 20, density = True, color = 'Red', alpha = 0.5) # plot the Cauchy p-values\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(['Gaussian','Cauchy'])\n",
    "plt.title('t-test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the above cell, but replace the t-test with the rank-sum test.\n",
    "# Make sure your histogram looks the same (aesthetically) as the one above.\n",
    "# hint: stats.mannwhitneyu(x = group1, y = group2)[1] returns the p-value for rank-sum test on group1 and group2\n",
    "\n",
    "?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that the rank-sum test is robust to the choice of distribution while the t-test suffers quite a bit when our assumptions are invalid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Permutation Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation tests provide another way to perform hypothesis testing. They are remarkably flexible, but can be computationally demanding. One benefit is the transparent way in which randomness enters the procedure. Let's see how they work when testing for a difference in medians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in Medians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that performs a permutation test for the difference of medians.\n",
    "# Inputs - your function should take four arguments:\n",
    "    # 1 - The first array of observations to be used in the test\n",
    "    # 2 - The second array of observations to be used in the test\n",
    "    # 3 - the number of permutations (set default to 1000)\n",
    "    # 4 - the test_type (set default to 'two-sided')\n",
    "# Outputs - your function should return a list of 3 objects\n",
    "    # 1 - The p-value\n",
    "    # 2 - The null distribution of differences between medians\n",
    "    # 3 - The true difference that was computed on the actual data\n",
    "\n",
    "def medians_permutation_test(array_1, array_2, num_perm = 1000, test_type = 'two-sided'):\n",
    "    true_diff = np.median(?) - np.median(?) # compute difference in medians of array_1 and array_2\n",
    "    null_diffs = make_array() # initialize null_diffs, the array in which the differences will be stored\n",
    "    merged_array = np.append(?, ?) # merge the two input arrays\n",
    "    # For loop to perform permutations\n",
    "    for i in np.arange(?):  # fill in the number of permutations to perform\n",
    "        # permute the elements of merged_array\n",
    "        shuffled_array = random.sample(list(merged_array), k = len(merged_array)) \n",
    "        group_1 = shuffled_array[:?] # get the elements of shuffled_array that serve as the new \"array_1\"\n",
    "        group_2 = shuffled_array[?:] # get the elements of shuffled_array that serve as the new \"array_2\"\n",
    "        diff_medians = np.median(?) - np.median(?) # compute the difference in medians of group_1 and group_2\n",
    "        null_diffs = np.append(null_diffs, ?) # append diff_medians to null_diffs\n",
    "    # If/else statements to allow us to perform the correct test for the desired alternative.\n",
    "    # Compute the correct p-value in each setting.\n",
    "    if test_type == 'two-sided':\n",
    "        # what fraction of the time is the difference from permutations as extreme as the observation?\n",
    "        p_val = np.sum(?)/?\n",
    "    elif test_type == 'greater':\n",
    "        # what fraction of the time is the difference from permutations greater than the observation?\n",
    "        p_val = np.sum(?)/?\n",
    "    elif test_type == 'less':\n",
    "        # what fraction of the time is the difference from permutations less than the observation?\n",
    "        p_val = np.sum(?)/?\n",
    "    else:\n",
    "        return \"test_type improperly specified; choices are 'two-sided', 'greater', 'less'\"\n",
    "        \n",
    "    return [?, ?, ?]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with observations from the normal distribution. Sample two groups of size 50 from \n",
    "# normal distributions with standard deviation 1 but respective means of 0 and 0.2.\n",
    "normal_perm = medians_permutation_test(array_1 = np.random.normal(0,1,50), array_2 = np.random.normal(.2, 1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a histogram of the null distribution with our true value noted by a vertical red line.\n",
    "# For each of the ?s, fill in with the proper element of normal_perm\n",
    "plt.hist(?, density = True)\n",
    "plt.axvline(x = ?, color = 'red', linewidth = 2)\n",
    "plt.xlabel('Difference in medians')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Perm. test, Gaussian. p-value is ' + str(?))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauchy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat with cauchy distributions with scale paramter 1 but location parameters of 0 and 0.2.\n",
    "cauchy_perm = medians_permutation_test(array_1 = stats.cauchy.rvs(loc=0, scale=1, size=50),\n",
    "                                       array_2 = ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the histogram from two cells above, but now for the test you just performed with Cauchy random variables\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Applying hypothesis testing to RNA-seq data for mammary tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for male and female samples of mammary tissue.\n",
    "# These data have already been normalized for you. Also note that they\n",
    "# are already on log2 scale.\n",
    "female_data = pd.read_csv('https://raw.githubusercontent.com/ds-connectors/Data88-Genetics_and_Genomics/master/Lab05/female_data.csv', index_col=0)\n",
    "male_data =  pd.read_csv('https://raw.githubusercontent.com/ds-connectors/Data88-Genetics_and_Genomics/master/Lab05/male_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data\n",
    "- individual_id: identification for each person\n",
    "- age: age in years\n",
    "- ENSGXXXXXXXXXXX.X: a gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual_id</th>\n",
       "      <th>age</th>\n",
       "      <th>ENSG00000227232.4</th>\n",
       "      <th>ENSG00000237683.5</th>\n",
       "      <th>ENSG00000239906.1</th>\n",
       "      <th>ENSG00000241860.2</th>\n",
       "      <th>ENSG00000237094.7</th>\n",
       "      <th>ENSG00000225972.1</th>\n",
       "      <th>ENSG00000225630.1</th>\n",
       "      <th>ENSG00000237973.1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000110375.2</th>\n",
       "      <th>ENSG00000258137.1</th>\n",
       "      <th>ENSG00000154102.6</th>\n",
       "      <th>ENSG00000214049.6</th>\n",
       "      <th>ENSG00000258545.1</th>\n",
       "      <th>ENSG00000102243.8</th>\n",
       "      <th>ENSG00000204335.3</th>\n",
       "      <th>ENSG00000233673.2</th>\n",
       "      <th>ENSG00000254184.3</th>\n",
       "      <th>ENSG00000124939.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1122O</td>\n",
       "      <td>64</td>\n",
       "      <td>9.472862</td>\n",
       "      <td>8.511856</td>\n",
       "      <td>3.912179</td>\n",
       "      <td>4.359106</td>\n",
       "      <td>7.543248</td>\n",
       "      <td>8.769976</td>\n",
       "      <td>13.782109</td>\n",
       "      <td>13.828460</td>\n",
       "      <td>...</td>\n",
       "      <td>2.660564</td>\n",
       "      <td>1.713130</td>\n",
       "      <td>7.370687</td>\n",
       "      <td>2.805017</td>\n",
       "      <td>7.191363</td>\n",
       "      <td>6.389709</td>\n",
       "      <td>8.304924</td>\n",
       "      <td>2.197593</td>\n",
       "      <td>8.078956</td>\n",
       "      <td>6.004972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11EM3</td>\n",
       "      <td>21</td>\n",
       "      <td>10.021887</td>\n",
       "      <td>11.158932</td>\n",
       "      <td>6.045909</td>\n",
       "      <td>7.177797</td>\n",
       "      <td>8.681529</td>\n",
       "      <td>6.089107</td>\n",
       "      <td>12.376671</td>\n",
       "      <td>13.098389</td>\n",
       "      <td>...</td>\n",
       "      <td>4.281051</td>\n",
       "      <td>1.455793</td>\n",
       "      <td>7.258705</td>\n",
       "      <td>6.381592</td>\n",
       "      <td>6.759111</td>\n",
       "      <td>9.557621</td>\n",
       "      <td>7.599735</td>\n",
       "      <td>2.049444</td>\n",
       "      <td>7.901291</td>\n",
       "      <td>6.226043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11EMC</td>\n",
       "      <td>66</td>\n",
       "      <td>10.141606</td>\n",
       "      <td>9.249839</td>\n",
       "      <td>3.843819</td>\n",
       "      <td>5.915275</td>\n",
       "      <td>8.287304</td>\n",
       "      <td>7.915531</td>\n",
       "      <td>12.982784</td>\n",
       "      <td>14.089816</td>\n",
       "      <td>...</td>\n",
       "      <td>1.991774</td>\n",
       "      <td>1.865565</td>\n",
       "      <td>8.253662</td>\n",
       "      <td>6.774388</td>\n",
       "      <td>6.311022</td>\n",
       "      <td>6.809710</td>\n",
       "      <td>5.497106</td>\n",
       "      <td>3.576248</td>\n",
       "      <td>8.006726</td>\n",
       "      <td>10.936709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11I78</td>\n",
       "      <td>51</td>\n",
       "      <td>10.124583</td>\n",
       "      <td>9.529601</td>\n",
       "      <td>4.379923</td>\n",
       "      <td>4.538749</td>\n",
       "      <td>7.911258</td>\n",
       "      <td>8.029622</td>\n",
       "      <td>13.936068</td>\n",
       "      <td>14.472028</td>\n",
       "      <td>...</td>\n",
       "      <td>2.694600</td>\n",
       "      <td>2.340492</td>\n",
       "      <td>7.690015</td>\n",
       "      <td>4.163559</td>\n",
       "      <td>8.097766</td>\n",
       "      <td>6.507936</td>\n",
       "      <td>7.602135</td>\n",
       "      <td>2.304819</td>\n",
       "      <td>7.129301</td>\n",
       "      <td>5.970833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11P81</td>\n",
       "      <td>31</td>\n",
       "      <td>9.089798</td>\n",
       "      <td>10.026867</td>\n",
       "      <td>4.902945</td>\n",
       "      <td>6.680241</td>\n",
       "      <td>8.185857</td>\n",
       "      <td>6.389890</td>\n",
       "      <td>12.891173</td>\n",
       "      <td>12.974815</td>\n",
       "      <td>...</td>\n",
       "      <td>3.184414</td>\n",
       "      <td>1.268261</td>\n",
       "      <td>7.843988</td>\n",
       "      <td>5.591702</td>\n",
       "      <td>8.260598</td>\n",
       "      <td>8.029097</td>\n",
       "      <td>6.402641</td>\n",
       "      <td>2.664616</td>\n",
       "      <td>8.043534</td>\n",
       "      <td>6.737102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  individual_id  age  ENSG00000227232.4  ENSG00000237683.5  ENSG00000239906.1  \\\n",
       "0         1122O   64           9.472862           8.511856           3.912179   \n",
       "1         11EM3   21          10.021887          11.158932           6.045909   \n",
       "2         11EMC   66          10.141606           9.249839           3.843819   \n",
       "3         11I78   51          10.124583           9.529601           4.379923   \n",
       "4         11P81   31           9.089798          10.026867           4.902945   \n",
       "\n",
       "   ENSG00000241860.2  ENSG00000237094.7  ENSG00000225972.1  ENSG00000225630.1  \\\n",
       "0           4.359106           7.543248           8.769976          13.782109   \n",
       "1           7.177797           8.681529           6.089107          12.376671   \n",
       "2           5.915275           8.287304           7.915531          12.982784   \n",
       "3           4.538749           7.911258           8.029622          13.936068   \n",
       "4           6.680241           8.185857           6.389890          12.891173   \n",
       "\n",
       "   ENSG00000237973.1  ...  ENSG00000110375.2  ENSG00000258137.1  \\\n",
       "0          13.828460  ...           2.660564           1.713130   \n",
       "1          13.098389  ...           4.281051           1.455793   \n",
       "2          14.089816  ...           1.991774           1.865565   \n",
       "3          14.472028  ...           2.694600           2.340492   \n",
       "4          12.974815  ...           3.184414           1.268261   \n",
       "\n",
       "   ENSG00000154102.6  ENSG00000214049.6  ENSG00000258545.1  ENSG00000102243.8  \\\n",
       "0           7.370687           2.805017           7.191363           6.389709   \n",
       "1           7.258705           6.381592           6.759111           9.557621   \n",
       "2           8.253662           6.774388           6.311022           6.809710   \n",
       "3           7.690015           4.163559           8.097766           6.507936   \n",
       "4           7.843988           5.591702           8.260598           8.029097   \n",
       "\n",
       "   ENSG00000204335.3  ENSG00000233673.2  ENSG00000254184.3  ENSG00000124939.4  \n",
       "0           8.304924           2.197593           8.078956           6.004972  \n",
       "1           7.599735           2.049444           7.901291           6.226043  \n",
       "2           5.497106           3.576248           8.006726          10.936709  \n",
       "3           7.602135           2.304819           7.129301           5.970833  \n",
       "4           6.402641           2.664616           8.043534           6.737102  \n",
       "\n",
       "[5 rows x 18483 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at female data\n",
    "female_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual_id</th>\n",
       "      <th>age</th>\n",
       "      <th>ENSG00000227232.4</th>\n",
       "      <th>ENSG00000237683.5</th>\n",
       "      <th>ENSG00000239906.1</th>\n",
       "      <th>ENSG00000241860.2</th>\n",
       "      <th>ENSG00000237094.7</th>\n",
       "      <th>ENSG00000225972.1</th>\n",
       "      <th>ENSG00000225630.1</th>\n",
       "      <th>ENSG00000237973.1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000110375.2</th>\n",
       "      <th>ENSG00000258137.1</th>\n",
       "      <th>ENSG00000154102.6</th>\n",
       "      <th>ENSG00000214049.6</th>\n",
       "      <th>ENSG00000258545.1</th>\n",
       "      <th>ENSG00000102243.8</th>\n",
       "      <th>ENSG00000204335.3</th>\n",
       "      <th>ENSG00000233673.2</th>\n",
       "      <th>ENSG00000254184.3</th>\n",
       "      <th>ENSG00000124939.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111YS</td>\n",
       "      <td>62</td>\n",
       "      <td>9.660841</td>\n",
       "      <td>9.629347</td>\n",
       "      <td>4.354931</td>\n",
       "      <td>6.332703</td>\n",
       "      <td>8.725843</td>\n",
       "      <td>7.161228</td>\n",
       "      <td>13.294878</td>\n",
       "      <td>13.462766</td>\n",
       "      <td>...</td>\n",
       "      <td>2.555231</td>\n",
       "      <td>1.385785</td>\n",
       "      <td>8.722501</td>\n",
       "      <td>4.939572</td>\n",
       "      <td>6.307022</td>\n",
       "      <td>8.251542</td>\n",
       "      <td>6.550133</td>\n",
       "      <td>1.162577</td>\n",
       "      <td>7.606887</td>\n",
       "      <td>6.372133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117XS</td>\n",
       "      <td>64</td>\n",
       "      <td>10.016344</td>\n",
       "      <td>8.827595</td>\n",
       "      <td>3.633330</td>\n",
       "      <td>5.929060</td>\n",
       "      <td>8.777160</td>\n",
       "      <td>9.067792</td>\n",
       "      <td>15.433316</td>\n",
       "      <td>14.903609</td>\n",
       "      <td>...</td>\n",
       "      <td>1.327906</td>\n",
       "      <td>-0.084137</td>\n",
       "      <td>6.643726</td>\n",
       "      <td>-0.019605</td>\n",
       "      <td>10.672042</td>\n",
       "      <td>1.769833</td>\n",
       "      <td>5.349703</td>\n",
       "      <td>1.642746</td>\n",
       "      <td>6.840945</td>\n",
       "      <td>1.434722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1192X</td>\n",
       "      <td>55</td>\n",
       "      <td>9.945722</td>\n",
       "      <td>8.807326</td>\n",
       "      <td>2.565472</td>\n",
       "      <td>3.627211</td>\n",
       "      <td>7.354884</td>\n",
       "      <td>6.506506</td>\n",
       "      <td>13.192797</td>\n",
       "      <td>14.119293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814260</td>\n",
       "      <td>-0.084195</td>\n",
       "      <td>7.391828</td>\n",
       "      <td>3.217245</td>\n",
       "      <td>6.760239</td>\n",
       "      <td>7.442327</td>\n",
       "      <td>6.687320</td>\n",
       "      <td>1.437959</td>\n",
       "      <td>7.227423</td>\n",
       "      <td>6.670872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11DXW</td>\n",
       "      <td>43</td>\n",
       "      <td>9.571294</td>\n",
       "      <td>7.956392</td>\n",
       "      <td>2.086012</td>\n",
       "      <td>4.953465</td>\n",
       "      <td>7.786824</td>\n",
       "      <td>8.237153</td>\n",
       "      <td>14.030577</td>\n",
       "      <td>14.149805</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374016</td>\n",
       "      <td>1.917362</td>\n",
       "      <td>8.895448</td>\n",
       "      <td>2.792236</td>\n",
       "      <td>7.337338</td>\n",
       "      <td>2.125317</td>\n",
       "      <td>5.342369</td>\n",
       "      <td>2.236973</td>\n",
       "      <td>7.350723</td>\n",
       "      <td>2.971686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11DXY</td>\n",
       "      <td>62</td>\n",
       "      <td>9.650121</td>\n",
       "      <td>6.140969</td>\n",
       "      <td>-0.161728</td>\n",
       "      <td>3.480555</td>\n",
       "      <td>7.386460</td>\n",
       "      <td>9.154622</td>\n",
       "      <td>14.999992</td>\n",
       "      <td>14.911233</td>\n",
       "      <td>...</td>\n",
       "      <td>2.843708</td>\n",
       "      <td>0.909213</td>\n",
       "      <td>5.720057</td>\n",
       "      <td>-0.019709</td>\n",
       "      <td>7.114112</td>\n",
       "      <td>1.110964</td>\n",
       "      <td>6.105266</td>\n",
       "      <td>2.040415</td>\n",
       "      <td>7.778753</td>\n",
       "      <td>0.154387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  individual_id  age  ENSG00000227232.4  ENSG00000237683.5  ENSG00000239906.1  \\\n",
       "0         111YS   62           9.660841           9.629347           4.354931   \n",
       "1         117XS   64          10.016344           8.827595           3.633330   \n",
       "2         1192X   55           9.945722           8.807326           2.565472   \n",
       "3         11DXW   43           9.571294           7.956392           2.086012   \n",
       "4         11DXY   62           9.650121           6.140969          -0.161728   \n",
       "\n",
       "   ENSG00000241860.2  ENSG00000237094.7  ENSG00000225972.1  ENSG00000225630.1  \\\n",
       "0           6.332703           8.725843           7.161228          13.294878   \n",
       "1           5.929060           8.777160           9.067792          15.433316   \n",
       "2           3.627211           7.354884           6.506506          13.192797   \n",
       "3           4.953465           7.786824           8.237153          14.030577   \n",
       "4           3.480555           7.386460           9.154622          14.999992   \n",
       "\n",
       "   ENSG00000237973.1  ...  ENSG00000110375.2  ENSG00000258137.1  \\\n",
       "0          13.462766  ...           2.555231           1.385785   \n",
       "1          14.903609  ...           1.327906          -0.084137   \n",
       "2          14.119293  ...           0.814260          -0.084195   \n",
       "3          14.149805  ...           1.374016           1.917362   \n",
       "4          14.911233  ...           2.843708           0.909213   \n",
       "\n",
       "   ENSG00000154102.6  ENSG00000214049.6  ENSG00000258545.1  ENSG00000102243.8  \\\n",
       "0           8.722501           4.939572           6.307022           8.251542   \n",
       "1           6.643726          -0.019605          10.672042           1.769833   \n",
       "2           7.391828           3.217245           6.760239           7.442327   \n",
       "3           8.895448           2.792236           7.337338           2.125317   \n",
       "4           5.720057          -0.019709           7.114112           1.110964   \n",
       "\n",
       "   ENSG00000204335.3  ENSG00000233673.2  ENSG00000254184.3  ENSG00000124939.4  \n",
       "0           6.550133           1.162577           7.606887           6.372133  \n",
       "1           5.349703           1.642746           6.840945           1.434722  \n",
       "2           6.687320           1.437959           7.227423           6.670872  \n",
       "3           5.342369           2.236973           7.350723           2.971686  \n",
       "4           6.105266           2.040415           7.778753           0.154387  \n",
       "\n",
       "[5 rows x 18483 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at male data. We see that for both, the rows are samples and the columns genes.\n",
    "male_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plot the mean expression for each gene in men versus that in women "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of each gene for men. (Recall np.mean(?, axis = ?)).\n",
    "# If you're unsure whether you computed the mean along the correct direction, you can always check \n",
    "# the length of the vector you produce\n",
    "\n",
    "# Don't forget to exclude the first two columns!\n",
    "\n",
    "# men\n",
    "mean_exp_men = ?\n",
    "\n",
    "# women\n",
    "mean_exp_women = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatterplot of the average expression in each gene for men and women. \n",
    "# Put women on the x-axis and men on the y-axis. \n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.scatter(?, ? ,alpha=0.1)\n",
    "plt.xlabel('Mean Expression Per Gene in Women')\n",
    "plt.ylabel('Mean Expression Per Gene in Men')\n",
    "plt.title('Mean expression in mammary by gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is more robust, implement what you learned about Mann-Whitney U tests in Part I to assess differential expression in men and women. Store the p-value for each gene and plot a histogram of the p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the storage of p-values\n",
    "gene_p_vals = []\n",
    "\n",
    "# Iterate through genes and perform Rank-sum test on each gene to compare\n",
    "# expression in men and women. Don't forget that df.iloc[rows, cols] will give you\n",
    "# the entries in the data frame corresponding to rows and cols\n",
    "for x in np.arange(?, ?):      # With which columns do we want to start and end?\n",
    "    female_gene_data = female_data.iloc[:,x] # get the female data for the gene\n",
    "    male_gene_data = ? # get the male data for the gene\n",
    "    p_val = stats.mannwhitneyu(?, ?)[1] # perform the rank-sum test between males and females for this gene\n",
    "    gene_p_vals.append(?)      # append p-value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gene_p_vals, bins = 20)\n",
    "plt.xlabel('p-value')\n",
    "plt.ylabel('Number of genes')\n",
    "plt.title('Mammary tissue in men/women')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of genes which are differentially expressed (p-value less than or equal to 0.05)\n",
    "n_genes_de = np.sum(?) # you may need to apply np.array to your p-values if you stored them in a list\n",
    "n_genes_de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Volcano Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same set of data, plot a commonly used visualization of RNA-seq data: the volcano plot. It is the -log10 p-value vs log2 median FC\n",
    "\n",
    "log2 median FC = log2(B) - log2(A) where B is the median of expression per gene in women and A is the median of expression per gene in men. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get -log10 p-values\n",
    "log_p_vals = -np.log10(?)\n",
    "\n",
    "# get log2 FCs. Remember np.median(df, axis = ?)\n",
    "# note that data are already log2-transformed\n",
    "log2_gene_fcs = np.median(female_data[2:], axis = 0)- np.median(?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make volcano plot.log2 FCs on x-axis and -log10 p-values go on y-axis\n",
    "plt.scatter(?, ?, alpha=0.2)\n",
    "plt.xlabel('Log2 FC')\n",
    "plt.ylabel('-log10(p-value)')\n",
    "plt.title('Female vs Male, mammary tissue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = Notebook('Lab05_differential_expression.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the assignment.\n",
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
